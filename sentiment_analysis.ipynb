{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_4BNteby9tYQ"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Bidirectional, Conv1D, Dense, Embedding, GlobalMaxPool1D, LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SG5fK1P0-w0K",
        "outputId": "f06306b8-05fe-4504-f442-0bb331435f1e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                               text\n",
              "0          0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  ...  is upset that he can't update his Facebook by ...\n",
              "2          0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3          0  ...    my whole body feels itchy and like its on fire \n",
              "4          0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\n",
        "    filepath_or_buffer=\"data.csv\",\n",
        "    encoding=\"ISO-8859-1\",\n",
        "    names=[\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"],\n",
        "    nrows=1600000\n",
        ")\n",
        "\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMHc12w-C35G",
        "outputId": "95879276-7028-4a7a-fad6-33b1f7da5c7a"
      },
      "outputs": [],
      "source": [
        "df = df[[\"sentiment\", \"text\"]] # Remove unused columns\n",
        "df[\"sentiment\"].replace(to_replace=4, value=1, inplace=True) # Change positive label from 4 to 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "K6GLHC40DLs5",
        "outputId": "328b10f6-86ea-4867-dff2-d6a0b8bd7a96"
      },
      "outputs": [],
      "source": [
        "ax = df.groupby(by=\"sentiment\").count().plot(\n",
        "    kind=\"bar\",\n",
        "    title=\"Label Distribution\",\n",
        "    legend=False\n",
        ")\n",
        "ax.set_xticklabels([\"Negative\", \"Positive\"], rotation=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dT5cnB0f-hns"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    text = text.encode(encoding=\"ascii\", errors=\"ignore\").decode(encoding=\"ascii\", errors=\"ignore\") # Convert to ASCII\n",
        "    text = text.lower() # To lowercase\n",
        "    text = re.sub(pattern=\"&amp[,;]\", repl=\"&\", string=text) # Clean ampersands\n",
        "    text = re.sub(pattern=\"#\\S+\", repl=\"[#]\", string=text) # Clean hashtags\n",
        "    text = re.sub(pattern=\"@\\S+\", repl=\"[@]\", string=text) # Clean mentions\n",
        "    text = re.sub(pattern=\"http[\\S]+\", repl=\"[/]\", string=text) # Clean URLs\n",
        "    text = re.sub(pattern=\"\\s+\", repl=\" \", string=text) # Replace all whitespace with single space\n",
        "    text = re.sub(pattern=r\"[^A-Za-z0-9 ]+\", repl=\"\", string=text) # Retain alphanumeric characters/spaces\n",
        "    text = re.sub(pattern=r\"(.)\\1\\1+\", repl=r\"\\1\\1\", string=text) # Replace three or more consecutive characters with two characters \n",
        "    return text\n",
        "\n",
        "df[\"preprocessed_text\"] = df[\"text\"].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "vtKnMtaH-i0w",
        "outputId": "7e84dbde-4dc7-4e57-ba80-8b16ae06dcbf"
      },
      "outputs": [],
      "source": [
        "# Positive sentiment wordcloud\n",
        "plt.figure(figsize=(20, 20))\n",
        "wc = WordCloud(max_words=2000, width=1000, height=500)\n",
        "wc.generate(\" \".join(df[df.sentiment == 1][\"preprocessed_text\"]))\n",
        "plt.imshow(wc, interpolation=\"bilinear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "VOUC8wkaFzCG",
        "outputId": "a9803899-f130-44a4-b31d-90bbae922c3c"
      },
      "outputs": [],
      "source": [
        "# Negative sentiment wordcloud\n",
        "plt.figure(figsize=(20, 20))\n",
        "wc = WordCloud(max_words=2000, width=1000, height=500)\n",
        "wc.generate(\" \".join(df[df.sentiment == 0][\"preprocessed_text\"]))\n",
        "plt.imshow(wc, interpolation=\"bilinear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "po5mZ-AqGVtA"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df[\"preprocessed_text\"], df[\"sentiment\"], test_size=0.1, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU4AXFP8Rc1J",
        "outputId": "21e9b5a9-f644-466c-8e87-1795e351e3c0"
      },
      "outputs": [],
      "source": [
        "W2V_SIZE = 300\n",
        "w2v_model = gensim.models.word2vec.Word2Vec(\n",
        "    [text.split() for text in x_train], \n",
        "    size=W2V_SIZE\n",
        ")\n",
        "len(w2v_model.wv.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S__9XRDNbMWY"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 60000\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters=\"\", lower=True, oov_token=\"[OOV]\")\n",
        "tokenizer.fit_on_texts(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HqItCyLbnfj",
        "outputId": "51a7cf85-9272-4125-a4b9-9bd663905aa2"
      },
      "outputs": [],
      "source": [
        "SEQUENCE_LENGTH = 300\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(x_train), maxlen=SEQUENCE_LENGTH)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(x_test), maxlen=SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJtoxibNcaZd",
        "outputId": "0401eab7-93c0-4849-f231-cf748d1e7558"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, W2V_SIZE))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if word in w2v_model.wv:\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n",
        "embedding_layer = Embedding(VOCAB_SIZE, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)\n",
        "\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(100, dropout=0.4, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(100, dropout=0.4, return_sequences=True)))\n",
        "model.add(Conv1D(100, 7, activation='relu'))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIiuw5XGcd1K"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=\"adam\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "             EarlyStopping(monitor='val_accuracy', min_delta=1e-4, patience=5),\n",
        "             ModelCheckpoint(\n",
        "                filepath='./tmp/checkpoint',\n",
        "                monitor='val_accuracy',\n",
        "                mode='max',\n",
        "                save_best_only=True\n",
        "            )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjastYIWckvG",
        "outputId": "837351f4-41ab-4ad0-aeda-865645407c1b"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x_train, \n",
        "    y_train,\n",
        "    batch_size=1024,\n",
        "    epochs=10,\n",
        "    validation_split=0.1,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "xj6iuhhmqhaY",
        "outputId": "65812b07-cd72-4f88-c1f8-e80ce46d111e"
      },
      "outputs": [],
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        " \n",
        "epochs = range(len(accuracy))\n",
        " \n",
        "plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.figure() \n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_KXHAcy8UNV",
        "outputId": "1caea5a1-4a2f-4a69-8a5b-0c0359ced45a"
      },
      "outputs": [],
      "source": [
        "# Save tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as file:\n",
        "    pickle.dump(tokenizer, file)\n",
        "\n",
        "# Save model\n",
        "model.save(\"model.hdf5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of twitter-streaming-pipeline.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "728bfd8bfd3dbe0de9e5a7a3237efd086f7b49e9872433e4e2a8ea8790f34158"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
